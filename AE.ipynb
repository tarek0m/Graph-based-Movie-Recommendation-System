{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import necessary libraries:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, GaussianNoise\n",
    "from keras.regularizers import l1_l2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"datasets/combined-u/combined_alpha(0.005)_train_ae.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the AE model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_ae(input_dim, hidden_dim, encoding_dim, noise_factor):\n",
    "    input_layer = Input(shape=(input_dim,), name='input')\n",
    "    noisy_input = GaussianNoise(noise_factor)(input_layer)\n",
    "\n",
    "    encoder_layer1 = Dense(hidden_dim, activation='relu', name='encoding_layer')(noisy_input)\n",
    "    latent = Dense(encoding_dim, activation='relu', name='latent',\n",
    "                           activity_regularizer=l1_l2(l1=0.001, l2=0.001))(encoder_layer1)\n",
    "\n",
    "    decoder_layer1 = Dense(hidden_dim, activation='relu', name='decoding_layer')(latent)\n",
    "    output_layer = Dense(input_dim, activation='sigmoid', name='decoder_output')(decoder_layer1)\n",
    "\n",
    "    autoencoder = Model(input_layer, output_layer, name='autoencoder')\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model using 10-fold cross-validation:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_dim = 35\n",
    "hidden_dim = 16\n",
    "encoding_dim = 4\n",
    "noise_factor = 0.5\n",
    "\n",
    "# Define cross-validation loop\n",
    "kf = KFold(n_splits=10)\n",
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "loss_scores = []\n",
    "fold_number = 0\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold_number += 1\n",
    "    print(f\"fold: {fold_number}\")\n",
    "\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "\n",
    "    autoencoder = create_ae(input_dim, hidden_dim, encoding_dim, noise_factor)\n",
    "\n",
    "    history = autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, shuffle=True, validation_split=0.1, verbose=0)\n",
    "\n",
    "    # Plot the validation loss over 100 epochs\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(val_loss) + 1)\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    best_epoch = val_loss.index(min(val_loss)) + 1\n",
    "    best_val_loss = round(val_loss[best_epoch-1], 4)\n",
    "    plt.plot(best_epoch, min(val_loss), 'ro', label='Best epoch')\n",
    "    plt.annotate(f'Best epoch: {best_epoch}\\nVal loss: {best_val_loss}',\n",
    "                 xy=(best_epoch, min(val_loss)), xytext=(best_epoch, min(val_loss)),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    plt.title('Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate the denoising autoencoder on the testing data for this fold\n",
    "    loss_score = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "    loss_scores.append(loss_score)\n",
    "\n",
    "    # Update best model if current model is better\n",
    "    if loss_score < best_mse:\n",
    "        best_mse = loss_score\n",
    "        best_model = autoencoder\n",
    "        print(\"Best model updated\")\n",
    "        print(\"Best MSE: {:.5f}\\n\".format(best_mse))\n",
    "\n",
    "# Plot the model\n",
    "# plot_model(autoencoder, to_file='images/autoencoder.png', show_shapes=True, show_layer_names=True)\n",
    "# plot_model(encoder, to_file='images/encoder.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Select best model based on average performance\n",
    "best_model_index = np.argmin(loss_scores)\n",
    "print(\"The best model was found at index #{0}\".format(best_model_index+1))\n",
    "print(\"Best MSE: {:.5f}\".format(loss_scores[best_model_index]))\n",
    "\n",
    "# Calculate the average performance metrics across all folds\n",
    "avg_loss_score = np.mean(loss_scores)\n",
    "\n",
    "# Print the average performance metrics\n",
    "print(\"Average loss score across all folds: {:.5f}\".format(avg_loss_score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save the best model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the best autoencoder\n",
    "autoencoder = best_model\n",
    "encoder = Model(autoencoder.input, autoencoder.get_layer('latent').output, name='encoder')\n",
    "\n",
    "# Print the model summary\n",
    "autoencoder.summary()\n",
    "encoder.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# autoencoder.save(\"models/autoencoder.h5\")\n",
    "# encoder.save(\"models/encoder.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
