{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import necessary libraries:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib as plt\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import collections\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T07:47:12.035627Z",
     "start_time": "2023-05-25T07:47:10.860264Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define functions:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def convert_categorical(df_X, _X):\n",
    "    values = np.array(df_X[_X])\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    df_X = df_X.drop(_X, 1)\n",
    "    for j in range(integer_encoded.max() + 1):\n",
    "        df_X.insert(loc=j + 1, column=str(_X) + str(j + 1), value=onehot_encoded[:, j])\n",
    "    return df_X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T07:47:12.052637Z",
     "end_time": "2023-05-25T07:47:12.070638Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read datasets:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading datasets...\n",
      "reading datasets done.\n",
      "\n",
      "handling dataset datasets...\n",
      "['UID' 'age1' 'age2' 'age3' 'age4' 'age5' 'age6' 'gender1' 'gender2'\n",
      " 'job1' 'job2' 'job3' 'job4' 'job5' 'job6' 'job7' 'job8' 'job9' 'job10'\n",
      " 'job11' 'job12' 'job13' 'job14' 'job15' 'job16' 'job17' 'job18' 'job19'\n",
      " 'job20' 'job21']\n",
      "handling dataset datasets done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataPath = 'datasets/seen/'\n",
    "\n",
    "print(\"reading datasets...\")\n",
    "\n",
    "# User-Item-Rating\n",
    "df = pd.read_csv(dataPath + 'ratings_before_5941.dat', sep='\\::', engine='python', names=['UID', 'MID', 'rate', 'time'])\n",
    "\n",
    "# User-Side-Information\n",
    "df_user = pd.read_csv(dataPath + 'users_before_5941.dat', sep='\\::', engine='python', names=['UID', 'gender', 'age',\n",
    "                                                                                             'job', 'zip'])\n",
    "\n",
    "print(\"reading datasets done.\\n\")\n",
    "\n",
    "print(\"handling dataset datasets...\")\n",
    "df_user = convert_categorical(df_user, 'job')\n",
    "df_user = convert_categorical(df_user, 'gender')\n",
    "df_user['bin'] = pd.cut(df_user['age'], [0, 10, 20, 30, 40, 50, 100], labels=['1', '2', '3', '4', '5', '6'])\n",
    "df_user['age'] = df_user['bin']\n",
    "\n",
    "df_user = df_user.drop('bin', 1)\n",
    "df_user = convert_categorical(df_user, 'age')\n",
    "df_user = df_user.drop('zip', 1)\n",
    "print(df_user.columns.values)\n",
    "\n",
    "print(\"handling dataset datasets done.\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T07:47:12.372238Z",
     "end_time": "2023-05-25T07:47:15.941235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   UID  age1  age2  age3  age4  age5  age6  gender1  gender2  job1  ...  \\\n0    1   1.0   0.0   0.0   0.0   0.0   0.0      1.0      0.0   0.0  ...   \n1    2   0.0   0.0   0.0   0.0   0.0   1.0      0.0      1.0   0.0  ...   \n2    3   0.0   0.0   1.0   0.0   0.0   0.0      0.0      1.0   0.0  ...   \n3    4   0.0   0.0   0.0   0.0   1.0   0.0      0.0      1.0   0.0  ...   \n4    5   0.0   0.0   1.0   0.0   0.0   0.0      0.0      1.0   0.0  ...   \n\n   job12  job13  job14  job15  job16  job17  job18  job19  job20  job21  \n0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n1    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n2    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0  \n3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UID</th>\n      <th>age1</th>\n      <th>age2</th>\n      <th>age3</th>\n      <th>age4</th>\n      <th>age5</th>\n      <th>age6</th>\n      <th>gender1</th>\n      <th>gender2</th>\n      <th>job1</th>\n      <th>...</th>\n      <th>job12</th>\n      <th>job13</th>\n      <th>job14</th>\n      <th>job15</th>\n      <th>job16</th>\n      <th>job17</th>\n      <th>job18</th>\n      <th>job19</th>\n      <th>job20</th>\n      <th>job21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T07:31:39.743841Z",
     "end_time": "2023-05-25T07:31:39.762842Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create graph:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using coef 0.005\n"
     ]
    }
   ],
   "source": [
    "alpha_coefs = [0.005]  # [0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045]\n",
    "\n",
    "for alpha_coef in alpha_coefs:\n",
    "    print(f'using coef {alpha_coef}')\n",
    "    pairs = []\n",
    "    grouped = df.groupby(['MID', 'rate'])\n",
    "    for key, group in grouped:\n",
    "        pairs.extend(list(itertools.combinations(group['UID'], 2)))\n",
    "    counter = collections.Counter(pairs)\n",
    "    alpha = alpha_coef * 3883  # param*i_no\n",
    "    edge_list = map(list, collections.Counter(el for el in counter.elements() if counter[el] >= alpha).keys())\n",
    "    G = nx.Graph()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T07:47:43.631784Z",
     "end_time": "2023-05-25T07:48:58.062623Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add edges\n"
     ]
    }
   ],
   "source": [
    "print(\"add edges\")\n",
    "for el in edge_list:\n",
    "    G.add_edge(el[0], el[1], weight=1)\n",
    "    G.add_edge(el[0], el[0], weight=1)\n",
    "    G.add_edge(el[1], el[1], weight=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T07:48:58.064623Z",
     "end_time": "2023-05-25T07:49:02.658773Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start pagerank\n",
      "start degree_centrality\n",
      "start closeness_centrality\n",
      "start betweenness_centrality\n",
      "start load_centrality\n",
      "start average_neighbor_degree\n",
      "file [0.005] done.\n",
      "******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_coef = 0.005\n",
    "\n",
    "print(\"start pagerank\")\n",
    "pr = nx.pagerank(G.to_directed())\n",
    "df_user['PR'] = df_user['UID'].map(pr)\n",
    "df_user['PR'] /= float(df_user['PR'].max())\n",
    "print(\"start degree_centrality\")\n",
    "dc = nx.degree_centrality(G)\n",
    "df_user['CD'] = df_user['UID'].map(dc)\n",
    "df_user['CD'] /= float(df_user['CD'].max())\n",
    "print(\"start closeness_centrality\")\n",
    "cc = nx.closeness_centrality(G)\n",
    "df_user['CC'] = df_user['UID'].map(cc)\n",
    "df_user['CC'] /= float(df_user['CC'].max())\n",
    "print(\"start betweenness_centrality\")\n",
    "bc = nx.betweenness_centrality(G)\n",
    "df_user['CB'] = df_user['UID'].map(bc)\n",
    "df_user['CB'] /= float(df_user['CB'].max())\n",
    "print(\"start load_centrality\")\n",
    "lc = nx.load_centrality(G)\n",
    "df_user['LC'] = df_user['UID'].map(lc)\n",
    "df_user['LC'] /= float(df_user['LC'].max())\n",
    "print(\"start average_neighbor_degree\")\n",
    "nd = nx.average_neighbor_degree(G, weight='weight')\n",
    "df_user['AND'] = df_user['UID'].map(nd)\n",
    "df_user['AND'] /= float(df_user['AND'].max())\n",
    "X_train = df_user[df_user.columns[1:]]\n",
    "X_train.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T07:49:02.662773Z",
     "end_time": "2023-05-25T09:02:59.002405Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save datasets:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"datasets/combined-u/x_train_alpha(\" + str(alpha_coef) + \").pkl\")\n",
    "print(f'file {alpha_coef} done.\\n******************\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
