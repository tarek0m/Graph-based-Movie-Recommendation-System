{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import necessary libraries:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, GaussianNoise\n",
    "from keras.regularizers import l1_l2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:30:14.983818600Z",
     "start_time": "2023-06-23T21:30:14.965818100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"datasets/combined-u/x_train_split_alpha(0.005).pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:30:16.384803600Z",
     "start_time": "2023-06-23T21:30:16.364978400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the AE model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def create_ae(input_dim, hidden_dim, encoding_dim, noise_factor):\n",
    "    input_layer = Input(shape=(input_dim,), name='input')\n",
    "    noisy_input = GaussianNoise(noise_factor)(input_layer)\n",
    "\n",
    "    encoder_layer1 = Dense(hidden_dim, activation='relu', name='encoding_layer')(noisy_input)\n",
    "    latent = Dense(encoding_dim, activation='relu', name='latent',\n",
    "                           activity_regularizer=l1_l2(l1=0.001, l2=0.001))(encoder_layer1)\n",
    "\n",
    "    decoder_layer1 = Dense(hidden_dim, activation='relu', name='decoding_layer')(latent)\n",
    "    output_layer = Dense(input_dim, activation='sigmoid', name='decoder_output')(decoder_layer1)\n",
    "\n",
    "    autoencoder = Model(input_layer, output_layer)\n",
    "    encoder = Model(input_layer, latent)\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, encoder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:30:17.221148600Z",
     "start_time": "2023-06-23T21:30:17.200140300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model using 10-fold cross-validation:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "Best model updated\n",
      "Best MSE: 0.03844\n",
      "\n",
      "fold: 2\n",
      "Best model updated\n",
      "Best MSE: 0.03501\n",
      "\n",
      "fold: 3\n",
      "fold: 4\n",
      "fold: 5\n",
      "fold: 6\n",
      "Best model updated\n",
      "Best MSE: 0.03438\n",
      "\n",
      "fold: 7\n",
      "Best model updated\n",
      "Best MSE: 0.03417\n",
      "\n",
      "fold: 8\n",
      "fold: 9\n",
      "fold: 10\n",
      "The best model was found at index #7\n",
      "Best MSE: 0.03417\n",
      "Average loss score across all folds: 0.03644\n"
     ]
    }
   ],
   "source": [
    "input_dim = 35\n",
    "hidden_dim = 16\n",
    "encoding_dim = 4\n",
    "noise_factor = 0.5\n",
    "\n",
    "# Define cross-validation loop\n",
    "kf = KFold(n_splits=10)\n",
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "loss_scores = []\n",
    "fold_number = 0\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    fold_number += 1\n",
    "    print(f\"fold: {fold_number}\")\n",
    "\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "\n",
    "    autoencoder, encoder = create_ae(input_dim, hidden_dim, encoding_dim, noise_factor)\n",
    "\n",
    "    history = autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, shuffle=True, validation_split=0.1, verbose=0)\n",
    "\n",
    "    # Plot the validation loss over 100 epochs\n",
    "    # val_loss = history.history['val_loss']\n",
    "    # epochs = range(1, len(val_loss) + 1)\n",
    "    # plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    # best_epoch = val_loss.index(min(val_loss)) + 1\n",
    "    # best_val_loss = round(val_loss[best_epoch-1], 4)\n",
    "    # plt.plot(best_epoch, min(val_loss), 'ro', label='Best epoch')\n",
    "    # plt.annotate(f'Best epoch: {best_epoch}\\nVal loss: {best_val_loss}',\n",
    "    #              xy=(best_epoch, min(val_loss)), xytext=(best_epoch, min(val_loss)),\n",
    "    #              arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    # plt.title('Validation loss')\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # Evaluate the denoising autoencoder on the testing data for this fold\n",
    "    loss_score = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "    loss_scores.append(loss_score)\n",
    "\n",
    "    # Update best model if current model is better\n",
    "    if loss_score < best_mse:\n",
    "        best_mse = loss_score\n",
    "        best_model = autoencoder\n",
    "        print(\"Best model updated\")\n",
    "        print(\"Best MSE: {:.5f}\\n\".format(best_mse))\n",
    "\n",
    "# Plot the model\n",
    "# plot_model(autoencoder, to_file='images/autoencoder.png', show_shapes=True, show_layer_names=True)\n",
    "# plot_model(encoder, to_file='images/encoder.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Select best model based on average performance\n",
    "best_model_index = np.argmin(loss_scores)\n",
    "print(\"The best model was found at index #{0}\".format(best_model_index+1))\n",
    "print(\"Best MSE: {:.5f}\".format(loss_scores[best_model_index]))\n",
    "\n",
    "# Calculate the average performance metrics across all folds\n",
    "avg_loss_score = np.mean(loss_scores)\n",
    "\n",
    "# Print the average performance metrics\n",
    "print(\"Average loss score across all folds: {:.5f}\".format(avg_loss_score))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:39:38.517139800Z",
     "start_time": "2023-06-23T21:33:11.228168500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save the best model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save(\"models/combined-u/autoencoder.h5\")\n",
    "encoder.save(\"models/combined-u/encoder.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T21:42:50.401663300Z",
     "start_time": "2023-06-23T21:42:50.367662500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
